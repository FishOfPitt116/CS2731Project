so what would you say to the person
listening that's going we'll wait a
minute a thousand bucks I can't do
anything with the thousand bucks there's
basically no where I can get rent you
know how am I gonna do anything close to
living right so for most people now a
thousand dollars is not going to be
enough but it will provide a cushion
right so that's sort of the whole idea
we're starting off with a thousand
dollars and that's not gonna be enough
so you'll still have to work so is that
the point is that the biggest confusion
related to all this that I think people
here ubi and they think that it's just
enough just enough so you can get by but
you're saying that's actually not really
what's going on here it may not be
enough initially I mean there may be
some places in the country not Los
Angeles but some places you could live
on a thousand dollars so if you're
really in a bad situation and you're
living in LA you could pack up and move
somewhere where maybe a thousand dollars
will allow you to survive right that's a
possibility but I think what most people
will do is they will take that thousand
dollars and they will use that to sort
of cushion the difficult times but they
will still be motivated to find a job to
start a business to do something they
would just have more options more
freedoms in terms of the choices that
they make yeah and that's why you
mentioned you're having Andrew Yang and
he actually calls this program the the
freedom dividend that's what he's named
it and that's exactly what it is it
gives you more options options
especially for someone that's living
month-to-month and really has no income
you know the the number of choices do
you have it in that scenario which is
very limited yeah I guess so much of
this has to do with just the strange way
we deal with politics so for example
you'll have you know politicians saying
we have to have $15 minimum wage and
then you can walk in to Burger King or
McDonald's now and order on an iPad
because they're basically saying alright
we're not gonna pay our people this much
so everything just becomes sort of uber
politicized right that's right and and
you know that that's why a basic income
is maybe a better approach because we
just give it to everyone and the problem
with raising the minimum wage is that it
may be
you know good for many workers but it
can actually also increase the incentive
to automate or or to do other things
right so it could actually result in
fewer jobs so giving people a basic
income and preserving the incentive for
them to still work or to do other things
I think is a very attractive proposition
when you sort of play out you know five
ten twenty years from now do you think
things are gonna just be beyond
drastically different in a way we really
can't think about because of the speed
of all of this because of everything
we've talked about here that we really
can't even envision the way is this I
think if you go out maybe a little
further than that twenty thirty years it
really really gets hard to imagine what
the future looks like my latest book
architects of intelligence wanted a
people it's a series of interviews with
the top people in AI one of the people I
talked to his Ray Kurzweil this is a big
futurist he thinks that it'll be alive
then yeah yeah yeah he absolutely thinks
he's gonna live forever he expects what
he calls the singularity something that
he's gonna completely change the whole
paradigm
he thinks did within just 10 years we're
gonna have human level artificial
intelligence and so forth so that's
possible the problem is that is very
unpredictable we don't know how fast all
of this is coming what I really focused
on is sort of the practical impacts of
AI and robotics and impact on the job
market some what I would say is that
within five to ten years we're gonna
definitely see a fairly dramatic and an
unambiguous impact on the job market and
on the economy and I think so ray is
basically gonna live long enough to see
the robots take over what one way or
another that's what he believes yeah you
know ray is he's already 70 but if
you've seen his photos recently he looks
a lot younger than then he did a while
ago so he's at least he's had some work
done yeah weathered and you know the
stuff under the hood is is is better or
not but right is he the only person
doing that sort of thing there must be
some other people oh no no you know in
Silicon Valley there are many people
very interested in this idea of living
forever and
and fast you know the Google people
Larry Page and Sergey and Peter tio is
very into this as well as even I think
played around with supposedly blood
transfusions and stuff like that so yes
the the Silicon Valley elite is you know
they're true believers in terms of this
idea that technology is going to
completely transform things and the
future is going to be dramatically
different from the past and then we're
gonna potentially even have the
possibility of living forever yeah can
you explain the singularity the
singularity basically means a point at
which technology takes off and begins
accelerating at a rate that becomes
incomprehensible to us so they it comes
from basically a black hole right the
the center of a black hole is what's
called a singularity where the laws of
physics break down and you can see
beyond that point so this the term
singularity was coined as a way to
express the idea that technology
technology reaches a point where it's
just completely unpredictable beyond
that point because things are moving so
fast and most people that think about
this associate that with the advance of
what's called super intelligence or
machines that are smarter than us not
only human level intelligence but a
machine that you know is smarter than
any human being may be dramatically so
may be so smart that it makes us look
like a mouse or an insect right so
that's where my sci-fi brain and every
movie that I've ever seen and every
dystopian future says well why would the
robots need us at that point exactly and
if anything wouldn't they just see us as
an annoying hindrance or a vestige of
the past and why wouldn't they want to
get rid of us right and that's a real
concern and that concern which is what
you see in the Terminator movies yeah
and and even more than that the the
related concern of what's called the
control problem which is that if we
created a super intelligence something
that's far beyond us maybe it won't
actively want to destroy us but it might
act in ways that are not you know right
you got that was right that was a robot
right and there are very very serious
thinkers that are focused on this the
money the most prominent ones is Nick
Bostrom who I also interviewed
this book architects of intelligence so
he you know believes that this is a real
issue and he's working on finding ways
to build systems that will be
controllable even if they become super
intelligence mm-hmm
so this is an issue that he's focused on
also the inherent problem being that if
you create the super intelligence it
probably at some point can get around
that I mean I know that's not mind
blowing to him but that's the whole idea
is that once we have a super
intelligence then you know it's so far
beyond us that we can't control it
anymore so what what people are working
on is basically principles of computer
science that will hopefully allow them
to build these systems in a way that
that will remain aligned with what we
want them to do even when they're super
intelligent right but is the problem
with that what we hit on earlier which
is maybe we here in America hopefully
figure out some systems that are gonna
make some sense but if the Chinese
figure out a system that's a little bit
different or just some random guy in his
garage in Mexico a like figures out some
other thing that we still have that that
basically there's just no way to manage
it seems yeah I think that's one of the
scariest aspects of this is that
competition and the fact that there
would be an incredible first mover
advantage to whoever gets there first
whoever builds the first super
intelligent system you know is gonna be
way ahead of everyone else and the
reason is is that most people believe in
what's called an intelligence explosion
or kind of iterative improvement where
basically once a machine which is human
level intelligence or gets beyond that
it's gonna turn its attention to its own
code right to building better versions
of itself so it's going to continuously
engineer a smarter version of itself and
that's something that could explode
rapidly so whoever gets there first
they're essentially uncatchable so
daddy's gonna set up a competitive
environment between the US and China and
Russia and so forth yeah so that's
something to worry about
but there are a lot of people working on
doing this in a safe way open AI is
another good example that's the the
organization that was set up by Elon
Musk right and some other people and
they're actively working on building
systems that
they basically they're trying to get
there first to be the first one to to
create a generally intelligent system
and to do it in a way that is safe so I
think that's a good thing there's
there's some real focus on that an
investment in that area but at the same
time there's also a lot of height people
like Elon saying some pretty
over-the-top things I do think that to
some extent that's a bit dangerous
because it again this is something that
is probably pretty far in the future I
would say probably at least 50 years of
away um there is a big debate over that
again in my latest book I interviewed
all these people I asked them this
question how soon are we gonna have a
computer that is at the level of a human
being in terms of intelligence and the
predictions I got ranged from 10 years
from Ray Kurzweil to nearly 200 years
Wow so it is a wide variation that the
average guess was about 80 years so the
end of this century so pretty far what
are the markers that cause people to
have a different response to that
question so why would someone like her
while say 10 and then someone else says
200 well you know there are a number of
breakthroughs that you have to have you
have to have machines that can learn the
way people learn right now as I said
we've got machine learning deep learning
which is highly dependent on lots and
lots of data and they're particularly
labeled data so you can train one of
these algorithms to recognize pictures
of a dog and you would give it maybe a
million photographs that had there was
you know these photos would be labeled
either there's a dog there or there's
not a dog there and you based on this it
could learn and eventually recognize
dogs in a superhuman level but that's
not the way a human child learns right a
human child you can you can point to a
dog and maybe you only need to do that
once before the kid needs to learn and
so one of the biggest initiatives is
teaching machines to learn from less
data and in an unsupervised way in the
way that that people can and then you've
got to have the ability to think
generally to conceive new ideas to be
creative to understand that one thing
causes another thing as opposed to just
two things being correlated to develop
counterfactuals to imagine I've got this
plan for the future but if I tweak this
one thing then this is what's gonna be
different these are all unique
human ways of thinking and it's going to
take a lot of breakthroughs before we
have a machine that can do all those
things and there's just a lot of
disagreement even between the very
smartest people working this field about
how long it's going to take for those
kinds of breakthroughs to happen how
concerned are you about the unbiased
that seems to be happening when it comes
to the algorithm so for example you know
the famous case that everyone talks
about is that if you google American
scientists that there is that it happens
to be it's just a function of things
that most America Samaritan scientists
who have done most of the breakthroughs
most not all happen to be white men but
that Google is unbiased so it includes
more black people or more women or
things like that which nobody has a
problem with no one in their right mind
has a real problem acknowledging that
there are scientists of every color and
gender and all those things but their
unbiased things that are that are not so
it's not really factual sort of what
we're putting in the algorithm and that
where that could lead us seems right
that's ultimately a decision for society
I suppose how we want to address those
issues some of them the whole issue of
bias in in algorithms is a huge issue in
artificial intelligence people are
working on reducing that and that that
operates in both ways I mean there
definitely an absolutely have been
legitimate cases of algorithms that are
biased against people of color and so
forth for example and gender - I mean I
know that one company for example
stopped using an AI system that was used
to screen resumes because it was biased
against women hmm and so forth and there
been other and where does that buyers
come from in a situation is you know
what happens is that again these are
systems that are learning from data
right but where does that data come from
originally it comes from people mm-hmm
so if people are biased in some way and
they're generating this data then an
algorithm a machine learning algorithm
comes along and and is trained on that
data it will pick up that bias so they
say we're the flaw in the system
absolutely more than anything else
really right but there is a hopeful note
there which is that fixing bias in a
human being is very hard right I mean we
don't really know how to
and we noted it does exist to some
extent but fixing it in an algorithm
could be a lot easier right it's
basically tweaking some bits so as we I
guess it depends who's doing it though
right exactly as long as as long as it's
done in a careful proper way but we
can't imagine a future where algorithms
as they're employed more may be as kind
of a check on decisions or maybe in some
cases actually making decisions it can
actually be a less biased world and not
a more biased world but you're right
there are a huge numbers of issues
running in both directions there yeah
well it's funny that that's sort of the
theme of all of this because I'm even
trying to sort of figure out as you're
talking are you optimistic about this or
or pessimistic about sort of where this
could all lead and I definitely sense
both sides there yeah I mean I tend to
be you know it's speaking more
holistically including you know there
are many many issues with AI things that
we should be concerned about bias is one
security abyss the ability of people bad
people to hack into a system and and do
evil things with it the potential for
weaponization is another thing that many
people are really really worried about
the idea that you can have autonomous
weapons not just one autonomous weapon
that might independently kill people
without a human in the loop but you
could have thousands of them swarming
right without that's this guy definitely
terrifying and this is something that
you know is is not really science
fiction I mean we were talking earlier
about super intelligence and
determinated where the machines actively
are making a choice to kill us that's
science fiction that lies far in the
future
but the idea of having thousands of
swarming autonomous drones that were not
intelligent independently but were you
know programmed by somebody else to do
something to attack someone or so so
basically something that could happen so
the idea being that okay Amazon moves to
drone delivery and then someone hacks
into the system and instead of these
drones dropping packages at our door
they're flying through our windows and
the street could be happy or whatever or
it could be someone you know
manufacturing a huge numbers of these
drones and and then installing
autonomous software
because the beyond the barrier to entry
here is pretty low I mean these are
these are weapons that some people could
be like weapons of mass destruction if
you had enough autonomous drones that
would be incredibly dangerous right now
if you look at something like nuclear
weapons in order for a country to have
nuclear weapons that you know you've got
to be a nation-state you gotta have love
you know resources on that level in
order to develop nuclear weapons but
these kinds of technologies where you're
talking you know and there's a lot of
overlap between the commercial sector
and things that could be done on the
security or military side you could go
on Amazon you could purchase a thousand
drones and then maybe you could you know
engineer them to be to be weapons or
something these are something that you
know there's a much lower threshold
there people in a basement somewhere it
could be doing this kind of stuff right
so it is wrong right now well I think
they know already but it is quite scary
and many people in the IR community are
very passionate about this in particular
there there's an initiative in the
United Nations to actually ban fully
autonomous weapons for example and the
real worry is not just that militaries
would use these kinds of weapons but it
would go beyond that and you would have
you know that kind of shady arms dealers
that now sell machine guns are selling
autonomous drones and so that they then
become available to terrorists and all
kinds of people is this is a really
scary scenario yeah one of the people I
interviewed
Stewart Russell who's a professor at UC
Berkeley created a youtube video code
slaughter bots that you can go on and
watch and it's really quite terrifying
and it shows you exactly what could be
done with huge numbers of swarming
autonomous drones and it's not again
it's not science fiction it's something
that could happen in the next 5-10 years
yeah do you are you familiar at all with
just sort of the anti technology
movement the more that you pay attention
to the technology movement and the
amount of people that are trying to
either get off the grid or limit the
amount of time on
right I mean I you know that that's I
think a natural response to a lot of
this I mean the the the worst example of
that is is Ted Kaczynski right the
Unabomber right we actually wrote a
manifesto that he was published I think
in the New York Times um but if you go
and read that manifesto this is a guy
that okay he's crazy right he's a
murderer all of this but if you read
that manifesto and not noted it was
written by him he's raising a lot of the
issues that we are now talking about you
know the issues that technology could be
a threat the issue that we might become
so dependent on this technology that we
lose our agency right our ability to
think for ourselves and so far so you
know even back then these people like
we're thinking about this and so this is
a natural response and one of the things
I fear the most is that if we don't find
a way to adapt to these technologies and
find a way to leverage all this progress
on behalf of everyone so that everyone
is better off there's gonna be a bigger
and bigger backlash people are gonna
turn against the technology and that
might mean not just going off the grid
and living you know as a hermit but
actually you know becoming much more
adversarial to the system and and that
might happen politically it might happen
in some places even in the form of
social unrest and so forth as things get
get bad enough if you really have
unemployment so I just think it's
critically important that we begin to
really address these issues and have a
honest discussion about them so that we
can avoid that scenario I assume you're
a fan of Black Mirror I haven't really
watched that but I've heard a lot about
it but but yeah that those kinds of
scenarios are you know science fiction
now but they are everyday becoming
reality yeah is there a sci-fi movie
that you think handles some of this in
the best way so not going all the way to
Terminator tomorrow but like there's
some movies that you think have sort of
teased out some of the the more
realistic surf yeah there are several
there's one movie a few years ago called
Elysium yeah which really got at the
issue of inequality because what
happened in oh that's the one with the
this yeah I love artificial ever
or and all the rich people yeah migrated
there on earth eqt foster became
basically you know a dystopian nightmare
all the regular people were stuck on
earth and that's you're seeing that
already of course with wealthy people
moving to gated communities and so forth
and elite cities like San Francisco
where things are becoming so unequal and
I really worry that that's the kind of
future we could have if we don't adapt
to this where you literally have got a
small number of incredibly wealthy
people that are benefitting from this
technology and or maybe using the
technology to protect themselves from
the masses I mean and everyone else is
literally left behind so that that's
sort of the ultimate irony of what's
happening in Silicon Valley right I mean
you just said it it's like San Francisco
they've got all these great minds are up
there creating all of this incredible
technology absurd amounts of wealth and
then if you go out on the streets of San
Francisco the amount of homelessness is
is through the room yeah yeah I mean
everything San Francisco and the Bay
Area is ground zero for this
technological revolution and then right
in their backyard you see you see the
inequality right you see what's
happening and this is something that's
gonna scale out right to everywhere
basically so we really need to get
control of that and if we don't it's I
think it's gonna tear our society apart
right it's gonna ultimately lead to some
real problems in the United States and
in other countries that are less stable
that have less you know solid
institutions that we have it it could be
even worse
you're gonna see government's fall and
things like that in some countries as a
result of this I think so it's really
something to be concerned about we need
we need to have some sort of a plan yeah
well that's what everyone's trying to
figure out right now is is what is that
plan that's opposed exactly and I think
this is one of the biggest challenges
we're going to face in the future you
know this is AI is going to be one of
the primary forces that shapes the
future it's going to be incredibly
disruptive and of course it's going to
happen in parallel with other things
climate change geopolitically the rise
of China migration right these are all
huge things that are happening already
all these things are coming at is in
parallel they're going to hit all too
together and I really worry about kind
of a perfect storm so we really need to
begin to get a handle on all this how
does the information war factored into
all of this you know one of the things
that people that watch this show or
always talk you know everyone's talking
about fake news all the time or that
we're just being handed things you know
the algorithm pushes us stories that are
favorable maybe to one side of the
political aisle or something like that
and then we're all going to also siphon
off into our own informational realities
basically and sort of we'll live in the
same physical world but digitally we're
gonna just accept different truths
exactly in that that that's what makes
it even more scary as to all of this
disruptions coming at us at a time when
we are just incredibly polarized we're
to some extent we're living in different
universes our ability to even talk to
each other seems to be limited how are
we gonna you know address these issues
how are we gonna respond to these
incredibly disruptive forces when we
can't even sit down and have a
conversation and agree on the same facts
right that's a real problem and and
there is evidence that is getting worse
and worse that's largely that's why I'm
doing this this is this is my little
firewall right here but exactly I hope
that there can be more of this because
we really need everyone and that
includes people on the left and people
on the right to be able to talk to each
other about this because otherwise we're
gonna have what we have now we've got it
we've got a congress that literally can
do nothing and and I'm concerned no
matter who wins in 2020 the presidency
you know it's likely the the Congress
will still be divided by the same
political polarization and social
polarization and social media
polarization will be there so how are we
gonna address these kinds of issues so
that gets to what you were talking about
earlier that you need something sort of
separate from the government in a way to
sort of be if if something could oversee
some of our ability to deal with this
technology it almost in a way it can't
be politicized because of the way our
system is right I mean is specifically
in terms of having a basic income I
think there are good reasons to put that
in the hands of a separate institution
and the Federal Reserve would be a good
example of that you've seen the Federal
Reserve which controls interest rates
right he's relatively independent right
now
although you know Trump is tried to to
to play around with it but you know if
it weren't for the fact that we had an
independent Federal Reserve I think we
would be much bigger trouble now than we
are and so there is an argument for
maybe taking some essential functions of
government away from the political
process and having a kind of a
technocratic approach to that all right
so my last question will be a two-parter
paint me a future if we get some of this
under control and we deal with this
technology maturely and properly give me
sort of where what do we look like in
about ten years and then if we lose
control and we don't do the proper
things and don't have the proper
firewalls what does the future look like
continue well I think that you know
maybe looking even beyond 10 years we
know one is how far do you want to go
well let's say 15 20 years but I think
that within that kind of a time frame
there's gonna be an unambiguous impact
on on a job market so if we don't get
control of this we will see unemployment
at least among some workers will see
greatly increased inequality even beyond
what we see now we will see more and
more anger more people left behind
possibly even social unrest as a result
of that we will see the rise of people
like Trump which you might characterize
as kind of a demagogue someone that
preys on the fear that people have right
maybe you know points to to immigrants
as opposed to technology as being the
primary cause of this and so forth right
those other people are stealing your job
a lot easier to always point to another
human being than it is to point to an
intangible force like technology so we
could have a future where you know
everything is just very very ugly and a
lot of people are really struggling
don't end me on that future and and the
other part of that though is that
there's also an economic aspect to that
that as people are unemployed or have
lower incomes they have less money to
spend right now they're not driving the
economy so the whole economy suffers so
we could have also a financial crisis a
recession perhaps people can pay their
debts and we get into a situation like
we had in 2008 right so that's that's
sort of
case scenario the best case scenario is
that we find a way to adapt to this
maybe it was something like a basic
income so we address this issue of
people not having jobs or not having
adequate income so they still have money
to spend they go out and they spend
their money in the economy there are all
kinds of new products and services and
exciting things for people to spend
money on there is incredible opportunity
for entrepreneurs for people like Elon
Musk's or the next Steven Steve Jobs to
create things based on this new
technology and people have the income
that they need to do buy these products
things do in large measure get less
expensive so people you know have have
greater purchasing power we have
enormous breakthroughs in science in
medicine we all live longer and
healthier lives so there are enormous
benefits to artificial intelligence it's
going to become the primary tool that's
used in scientific research in solving
problems like climate change developing
new forms of clean energy you know
medical breakthroughs all of that the
key thing is that we want to make sure
that we get that stuff and then we get
it for everyone in other words we want
to be able to leverage it on behalf of
everyone rather than just a few people
and I think that if we can find a way to
navigate through this that it's
incredibly optimistic and and where it
kind of ends up in the far future is
maybe something like Star Trek right
where where you've got what has been
called kind of the post-scarcity economy
an economy of abundance where you know
people don't have to worry about the
basics of life anymore that people you
know focus on other things right I mean
in Star Trek you've got the materializer
right you everything is basically free
people don't have to work a nine-to-five
job to survive they're out traveling the
universe or whatever doing things that
are genuinely meaningful to them and I
think that's sort of the vision that we
should have as we you know anticipate
the development of these technologies
but in order to get there we've got to
be honest there's some serious lift
about what the implications of this is
we need to have an honest discussion and
come up I think ultimately with some
real policies to address
the risks and the downsides that are not
going to come with this progress so we
shall see these are the three words that
will sort of take us out of this one we
should probably do this every year you
want to do one of these every year
absolutely and just pick up on all the
incremental progress and then I suppose
if everything you're saying is right one
year we're gonna do it and everything
will look so absolutely different we
won't even be able to look back and make
any sense of all right once we get past
that singularity yeah be different I
look forward to it and for more on
Martin you can follow him on Twitter at
M Ford future
[Music]
