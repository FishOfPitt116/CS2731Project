joining me today is the author of The
New York Times bestseller rise of the
robots technology and the threat of a
jobless future
Martin Ford welcome to the Rubin report
thanks for having me I'm glad to have
you here sir because dystopian futures
robots Skynet all of it very much in my
wheelhouse and I want you to explain it
all to me are you ready yes definitely
all right let's do it so first off
before we dive directly into robots and
AI and all that just tell me a little
bit about your background what brought
you to writing a book like this okay so
I studied computer engineering in
college and then I worked as an engineer
a design engineer for several years then
I went back and studied business
eventually I ended up starting and
running a small software company up in
Silicon Valley and I ran that for many
years but even in the course of running
that I saw the impact that all this
technology was having on on jobs at my
business and that businesses like it and
that really got me thinking about this
issue and so about 10 years ago in 20
2009 I wrote my first book called the
lights in the tunnel which really argued
that artificial intelligence was going
to be the next big thing in computing
and then it was going to have a dramatic
impact in particular on the job market
and that book did well enough that it
led to an opportunity to write this book
in 2015 which really got you know quite
a bit of attention and since then I've
kind of shifted my career to really be a
futurist focused on what AI and robotics
means for society and for the economy
and especially for the job market so I
think there going to be some huge
challenges there for us right so we're
gonna unpack all of that stuff but when
you were writing about this in 2009
where people say oh now this is just
pure science Vidya I mean I this was an
issue it was very much off the radar
back then it came with a fair amount of
stigma and stigma and the reason is that
this concern or fear that machines might
take a lot of jobs and there might be
unemployment it's it's an old issue it's
come up many times in the past going all
the way back to the Luddites right in
England 200 years ago and so there's
actually this term neo-luddite for a
person that is once again worrying about
this issue and
it was quite stigmatized so in 2009 when
I wrote the book you know I was one of
the the earliest people to get out there
with this but since then things have
definitely changed and I see a lot of
people much more concerned about this
even professional economists and so
forth so there definitely has been a
shift in mentality over this last ten
years when we've seen things like like
the advent of self-driving cars they
look like they're gonna be arriving soon
and so forth what markers were you
seeing back in 2009 or a little bit
before that even that we're sort of
pushing you in this direction but the
most important thing is what you might
call Moore's Law the fact that the power
of computers is accelerating doubling
every two years and it was obvious that
computers were going to get dramatically
more powerful and there had to be an
application for that it has to be
something you can do with that and it
became obvious to me that artificial
intelligence was going to be the thing
and an AI means essentially solving the
same kinds of problems that the human
brain can solve right enemies machines
that in a limited sense are taking on
cognitive capability they're beginning
to think and that means that technology
is going to begin to compete with and
substitute for human being human beings
in a unique way something that we've
never seen before and is that scales
across the whole economy as all kinds of
jobs skilled jobs and unskilled jobs I
think that it becomes pretty clear that
you know it's gonna have dramatic
implications so when people think about
robots I think like there's a there's a
few different ways you can think about
that you can sort of think about AI
which is sort of the same orphis thing
that people sort of don't contextualize
into a physical object then they think
of robots they think of like you know
c-3po and r2d2 and everything else what
if you were just saying robots what what
exactly are you talking right I
especially in this book rise of the
robots I use the very broad meaning for
that basically to mean anything that is
automating something and taking over you
know things that people can do and very
often that's just gonna be software if
you want to be more precise and
technical a robot is when you take
artificial intelligence and you put it
into a physical machine that can
physically manipulate the environment
but what we're talking about is much
broader than that so we're gonna you
know we're already seeing people like
lawyers and doctors being impacted and
it's not physical robots it's something
just software artificial intelligence
and actually you know building physical
robots that have dexterity that can
manipulate the the environment that's
actually one of the hardest aspects of
this and in some ways that where it may
be where progress is gonna be slowest
where in knowledge type work you know
someone that's sitting in front of a
computer doing some routine task
cranking out the same report again and
again that may actually be much easier
to automate then than something physical
so that's interesting so the the idea
part of it is easier to replicate than
the physical part even though you'd
think that just building a robot that
can move the way you want it to move or
something so that seems technically
easier than figuring out how to think
like humans now it seems like that from
our perspective very often the reason is
that to do these knowledge-based jobs
requires a lot of Education and training
right but actually once you implement
the technology it actually can often be
the the reverse the hardest thing to do
is to build a physical robot that has
dexterity that has visual perception
that can can move around the way a
person does think to build as you said
the kind of robot like c-3po from Star
Trek that's totally science fiction we
don't have anything remotely like that
it seems like we're now and again you
see a video on YouTube where they're
getting a little closer you know they've
got it right but you know jumping over
something and ducking under something
exactly you see those robots in
particular from a company called Boston
Dynamics it's doing very impressive
things but those videos are highly
choreographed the robots are controlled
by someone that's outside the picture
this is not a thinking autonomous robot
running around doing stuff by itself
okay so we're not in Terminator land
just yet not not anytime soon at all
that's far in the future but that you
know we shouldn't allow we shouldn't be
distracted from the fact that there are
things happening now they're gonna have
a really dramatic impact but it's not
the science fiction stuff do you see in
the iRobot million and stuff like that
right so how much of the conversation is
about all of this is about what you
referenced a moment ago about just the
speed of technology and that every two
years the power doubles and all that
that were
walking around with iPhones or so you
know we may have supercomputers in our
pocket and the way we can transmit
information across the globe like that
and and just how much of this is just
related to speed more than right that's
you know a very big part of it it is not
just the speed of computers that have
gotten faster and smaller of course and
now they're in our iPhones but it's the
speed of communications bandwidth it's
memory capacity so we've seen this very
broad-based acceleration and technology
and that's a huge part of it the other
things is that that there have been some
breakthroughs in in artificial
intelligence especially in the hottest
area of AI which is called deep learning
or deep neural networks we've seen
dramatic progress there and that's the
thing that's really revolutionising the
field and and the other thing that's
happened is that we are now throughout
our whole economy and society collecting
huge amounts of data right there's all
this data out there that wasn't there
before and this data is basically the
resource that is used to train these
smart algorithms and that's what
artificial intelligence looks like right
now it's primarily machine learning and
this is just gonna be incredibly
disruptive yeah so it's part of the
potential problem here that we're
building things that will be more
powerful than us and we don't really
understand that so it's like we're
putting so much information in our
brains oh maybe our actual physical
brains can't take all this in like we
don't have enough RAM in our physical
brains for all of the information that
we're constantly slamming ourselves to
well it's definitely true to these smart
algorithms I mean they can look at you
know huge amounts of data millions and
millions and millions of data points
right which no human being could do so
we already have algorithms that in a
very narrow sense in terms of doing very
specific things are superhuman right
they can vastly outperform what any
person does and they do things that we
don't really understand it good example
of that would be Wall Street right where
you've got these trading algorithms that
can actually look at machine readable
news I mean companies like Bloomberg
actually make news products that are
designed for machines not for people
these our rhythms can read that news
and then analyze it and then trade on it
within you know tiny fractions of a
second so that would be an example of
where technology is already getting
ahead of what we can understand yeah
what do we do to rein some of it back in
occasionally well I you know there any
lower is it just once we start the
process with anything like this we just
don't know where it you know it's a
difficult question you know they're
gonna be places where we're gonna need
regulation
you can't just rein it in I mean it's
progress it's happening it's happening
in part because of a competitive dynamic
right within capitalism between
companies between Google and Facebook
and Goldman Sachs all competing to build
delay this technology there's also a
competition between United States and
China all of that is going to push it
forward relentlessly and trying to stop
it it's probably kind of a fool's errand
it's probably not possible and and
probably not not really advisable what I
think we have to do are find ways to
adapt to all of this progress and in
some places that may mean certainly
regulation and in other cases it will
mean finding ways to address issues like
unemployment and inequality that will
result from all of this progress yeah so
let's just define some basic terms
because I think we end up throwing out a
lot of big terms here and then people
are confused so just when people are
talking about the algorithm can you just
explain in simple terms what is the
algorithm well and as we're doing this
on YouTube right now we're always
obsessed with the algorithm an algorithm
is just essentially a computer program
it's something that goes step by step
and does something what we've seen
recently though is the emergence of a
new kind of algorithm called machine
learning algorithms and this is what's
really disruptive and the difference
between a machine learning algorithm and
a traditional computer programming
algorithm is did you know historically
some programmer has has sat down and
told the computer to do what to do step
by step with machine learning instead
you've got a smart algorithm that looks
at lots and lots of data and then
figures out for itself what to do so in
essence it's kind of program its program
its itself right yeah so is there a way
to control
then well you is it just actually
uncontrollable because once once it's
learned enough it just doesn't need the
player it's not so much that it's
uncontrollable but that you know we
don't really want to control the whole
point is to to unleash it and let it
learn and do things that doesn't mean
that it's in any sense out of control or
it's a danger to us or anything like
well I would the reason I was asking was
sort of through it through a YouTube
algorithm lens like one of the things
we're finding out is they just want to
keep you clicking all the time right you
know where we put out a long-form show
people are gonna watch a full hour of
our discussion that's not really what
the algorithm wants it wants you from
the way we understand it from some
insiders they want you to constantly be
clicking on videos and basically fall
into this click call to just keep the
machine going more and more and more now
I understand why they want that sort of
attention going in different places and
all that but for what I do I don't love
the algorithm at the moment if that
means right right so that depends on how
they optimize the algorithm but what's
happening there is that you've got
millions and millions of people watching
youtube videos and if they watch an
entire video then that will create a
data point that says you know they were
really interested in this if they if
they start watching you know you know
for a brief time and they click away
then it'll show that they're less
interested and then an algorithm comes
around and looks at millions of those
data points and and can make
recommendations for other videos and and
as you said I think what we've seen is
that the video shown to people become
more extreme right so if you're
interested in something and then you'll
get a more extreme version of that and
that's how to get people to click and a
lot of people have been you know raising
the alarm over that because that is kind
of radicalizing people right so what do
you do about that if you're if you're a
programmer and you're at YouTube and you
don't want people to be radicalized or
just you know even if you just don't
want people to have to just be endlessly
clicking like there's this game to keep
people addicted to all these things and
it's like I understand that we could put
out a zillion clips so I could you know
I could chop everything into two minute
things and we could put them out and it
would probably help us in terms of views
and all of those things but I just don't
want to play that game right technically
I don't think that's a difficult problem
that depends on what the designer wants
to do that but the whole problem is that
the algorithms are designed to make the
most money for Google right that's
what's driving her so it's not I don't
think it's a computer design problem is
it's a capitalism problem a
profitability problem it's the fact that
that Google is a publicly traded
companies and it you know it's investors
want it to make as much money as
possible and that's what drives it to
design algorithms that maximize
profitability so keep your clicker that
that may be the kind of place where
maybe some regulation has to come in and
say you know well you're gonna have to
put some constraint on this if Google
doesn't make the decision to do it so
yes I mean this is where I'm not a
regulation guy but it's like they're
pushing me to my limits I mean this is
what I keep saying about all the tech
companies right now when it comes to
censorship and everything else it's like
they're not giving us much of a choice
here right I mean it's a challenging
problem for sure - to figure out you
know for AI to figure out what's in a
video and in terms of is there something
there that should be censored or not
that's the decision they're making and
that's that's quite different from from
just optimizing getting people to watch
you videos because in order to do that
you know you don't care what's in the
video that's the whole problem right
right it's just tracking statistics but
if you actually want to analyze what's
in a video is there something there it
is dangerous are you inciting people to
violence or something like that for
artificial intelligence to figure that
out is still much much harder now that
that's why we're running into this
problematic how is deep learning
different than artificial intelligence
that's that's just the next level of
artificial deep learning is a kind of of
artificial intelligence is right now the
hottest area of AI and deep learning or
deep neural networks basically means a
system that is loosely designed on the
way a brain would work it has artificial
neurons that are roughly similar to to
the neurons in your brain and that's the
way it works and this is an idea that's
been around you know for since the 1950s
at least but just within the last six
years or so we've seen just an explosion
in this technology and we've now got
systems that can translate languages
from Chinese to English that can
and do better than people at recognising
visual images we've got with radiology
systems that can look at medical images
and find cancer there and in some cases
can do that better than human doctors so
this is absolutely absolutely the
hottest area of AI it's also what's
enabling self-driving cars for example
so is this the great catch-22 of all of
robotics is that it's doing these
incredible things and then as you talked
about in the book it's gonna put a lot
of people out of work as well I think
that's one of the the real problems with
it I mean and you know we're ultimately
going to have to make a choice as to
whether we want to allow that progress
to continue and get the enormous
benefits of that progress but if that's
gonna come at a cost of making some set
of our population unemployable or or
maybe de-skilling jobs to the point
where people just don't have adequate
income even if they don't even if they
do have a job hmm then we've got to find
a way to adapt to that right and that's
why for example I've talked a lot about
a universal basic income is your own
possible approach to that but I'm very
much against the idea that we should
stop progress because this is where we
are you know this is what the rest is
gonna look like in the future we don't
want to stop it because progress is the
thing that has made us better off over
is there any evidence that ever in
history you could stop progress actually
even if we wanted to stop it right let's
say you laid out the greatest case why
this thing is gonna run out of control
it's gonna put half of us out of
business
you know the income inequality is gonna
go crazy poverty etc etc is there any
case where technology existed that we
somehow put the put the brakes on it I'd
be quite skeptical that we'd be able to
do that again in part because of
competition not just between companies
but between countries maybe we would do
it but then China didn't put the brakes
on and they would pretty soon be vastly
ahead of us right so that would be a
problem is that the catch-22 then for
regulation because it's like we may try
to regulate some of it but if China is
not regulating it or if they're exactly
that one of you know that's one of the
biggest problems is that you would you
would put your country at a disadvantage
unless you could do it on a global basis
and of course doing anything on a global
basis is incredibly hard as you see with
climate change for example
so again my perspective is that rather
than trying to slow it down what we
should do is find a way to adapt to it
let just let it run but understand what
the implications are gonna be and figure
out a way to adapt to that
yeah and that's where the idea of a
basic income comes in so I want to talk
a little bit more about ubi but before
we do that can you talk a little bit
just about how this has affected certain
industries and how some industries
haven't quite been affected yet right so
in general the point that would make is
it is gonna affect everything I mean
artificial intelligence is gonna be like
a utility it's gonna be like electricity
right and no one says what industries
are most impacted by electricity I mean
you know everything relies on
electricity right and the same will be
true of artificial intelligence and
machine learning so in the long run is
everywhere in the near term clearly you
know manufacturing has already been
impacted by automation generally we've
seen a dramatic decrease in advanced
countries and the number of people
employed in manufacturing that's going
to continue the robots and the
automation used in factories is gonna
get a lot more effective more dexterous
they'll be able to do the jobs that
right now only people can do but it's
gonna scale to many many other areas in
finance it's gonna have a dramatic
impact a lot of white-collar jobs there
where people are sitting in front of a
computer cracking out reports or
something right
recently I saw something that a CEO of
Deutsche Bank one of the big banks said
he thought he could get rid of half of
his employees in a relatively near
future using using this technology
healthcare is an is an area where it's
gonna be slower because it's really hard
you've got doctors and nurses that need
to engage with patients on a one-on-one
basis right and provide a lot of
individual human-like service and it's
been and that's one of the reasons that
healthcare costs are so high in the
United States right now because we have
not seen the kind of productivity
increases there that we've seen in
saying manufacturing right so what what
could we do to see that well we're
beginning to see evidence of that as I
mentioned you've got systems now that
can read medical images so you're going
to begin to see the introduction of
artificial intelligence in medicine
think that it will for the most part
least in the near term it's not going to
completely replace doctors but it will
become kind of a second opinion
it will run alongside a doctor you know
always be there we'll make every doctor
be able to perform at the level of the
best doctor right because because
there'll be this incredible intelligence
there so that will be of enormous
benefit there and then eventually if you
just extrapolate that down the road it
could replace the doctor to write a
short surgery like in the movie alien
and a million other things exactly amano
i would say in general doctors are
relatively safe because they are highly
regulated right there are all kinds of
rules about medicine and and you need to
have a doctor or a pharmacist there and
those go so those rules are relatively
protect protected where if you're a
white-collar job in some corporations
sitting in a cubicle somewhere you don't
have any protections at all so for that
reason I would worry a bit less about
doctors disappearing in an inner term
but you know in health care there
definitely are gonna be lots of
applications you already see robots in
hospitals delivering things you see
robots beginning to be used in elder
care looking after older people which is
certainly one of the biggest
opportunities because we have this aging
population Pharmacy robots who are huge
things they're already robots that do
you know thousands and thousands of
prescriptions in hospitals and so forth
very efficiently so this is coming it
will take a little bit longer in
healthcare than in some other areas but
eventually it's going to be everywhere
in retail you know they're there
Walmart is beginning to introduce robots
and of course retailing general is
migrating more and more toward Amazon
yeah which in theory means that jobs you
know MIT they might move from a retail
store to an Amazon warehouse but once
the jobs go to that Amazon warehouse now
they're in a very controlled environment
mm-hmm and there are already lots of
robots there and those robots are gonna
get dramatically better in the next five
or ten years so in effect you could have
a giant Amazon warehouse that we've all
driven by one of these these huge
monstrosity x' and it could basically be
run by all robots and your
a lot fewer people I mean right now
inside those room inside those
warehouses you have huge numbers of
robots and the robots will do something
like bring a whole shelf of inventory to
a worker but then the workers got to
reach in there and grab the item off the
shelf mm-hmm and put it in a box because
the robot right now can't do that it
doesn't have the visual perception and
the dexterity to do that yeah but that
will change over the next five to ten
years and so those environments are
going to become a lot less
labor-intensive that's not to say
they'll be fully automated but they're
gonna be fewer jobs there and that's
something to worry about because this is
one of the brightest areas right now for
job creation right so we're gonna so
we're gonna watch a certain sector or
many sectors of jobs just disappear
altogether and yet at the same time I
guess the counter-argument or the people
that would say we shouldn't be so
alarmed about this would say well all
the cost of everything will go down
because the robots will be able to do
things that are much more efficient
cheaper level right so people won't need
as much disposable income that sort of
thing that's right I mean that that's
absolutely true there I I'm very
skeptical that that kind of solves the
problem no me you can think about it if
you don't have a job at all then your
income is zero it doesn't matter doesn't
matter how the other thing is that the
really big ticket items the things that
really are putting people under water
are housing education health care and
these are exactly the areas where
technology is at least in the short and
medium term gonna have the least impact
right I mean housing in particular
someday we might have big 3d printers
that make it really cheap to produce
housing but but there's still a problem
with land right and if you're in Los
Angeles or up in San Francisco then
there's no land right it's already you
know you know it's already very scarce
and that's what drives property values
so high so you can't solve that problem
necessarily just with technology yeah so
as incomes fall you know many people are
not gonna have the income to really
cover it the basics and that that's
gonna be a big problem okay so that's
the right transition then to universal
basic income so my my default position
on ubi and I've heard arguments on both
sides and I think I told you I've Andrew
yang coming in soon and we'll discuss it
further
my default position is that
if you give people just enough to
survive that you're sort of stealing
just like the most basic human right of
just like go get something for yourself
and that it's gonna create this class of
people sort of not by their own fault
that we'll just have the bare minimum to
get by and then they'll be able to stay
at home and play video games and watch
porn and basically do nothing all day
long and will and that's actually taking
for something from them rather than
giving something to them that's sort of
my sort of like high-level philosophic
position on it right the argument I
would make is that once a society who
reaches a certain level of prosperity as
we have if you want to continue to have
capitalism and a market it's very
important to have the kind of incentive
that you're alluding to there yeah but I
would argue that maybe the incentive
doesn't have to be so daunting that if
you don't work you're living on the
street or eating out of garbage cans
right that maybe it's enough to say that
you can basically survive if you're not
motivated but you're not gonna have a
terrific life you're not gonna have a
great life and I think that that a
number of studies have been done with
basic income that showed that when you
give people this money they don't in
fact just drop out and stay home and do
nothing they are actually motivated to
do something more they invest in their
family and education they work if they
can they maybe start a small business so
actually if you give people that basic
safety net you can create an environment
where people are actually more willing
to take risks so for example they might
start a new business
they might be willing to leave a safe
job where they're not learning anything
they're not growing and work for a
start-up company do something more risky
right but is the inherent problem that
then if they start getting some success
then they lose the ubi and no no that's
that's yeah the whole solution yeah
to a basic income and that's what makes
it different from other forms of safety
is that it is unconditional in the sense
that everyone gets it now what that
means is that if I get my basic income
and I choose to just play video games
then I'll have that basic income but if
someone else is more ambitious they get
their basic income and they go and work
even if it's only part-time they
to small business then they they get the
basic income and they also get that
additional income we don't tax it away
at least not at the lower level so the
key point is that the person that is
productive that is willing to do
something to work will always be better
off than the person that does nothing
right and that's really key to it
because the problem with our existing
social safety net is exactly what you
said that if you do something find a job
then you lose those benefits yeah and so
that the cliff has to be really hiding
to be willing to leave right and that's
exactly what's called a poverty trap
right you get into a situation where you
look at the options around you and and
anything you do doesn't make you better
offer you know and she works often so
you're stuck there you can't move the
worst possible example of that in United
States is the Social Security disability
program right which is intended for
people to injured on the job and then it
can't work but actually a lot of people
now are gaming it probably because
they're desperate they need an income
and so they'll go and tell their doctor
they've got pain in their back or
something and they'll get through the
loops and they'll get on to this program
which gives you an income once you get
there you can't even be seen to be able
bodied people are worried even to go and
work in their garden or something
because someone will see them and then
they'll lose their benefits right so
that's a really terrible example of this
kind of income where a basic income we
give it to everyone and it's
unconditional and then we encourage
people to do more right and that that
that's really important that's one of
the strongest arguments for a basic
income scheme yeah so let's get into
some of the nuts and bolts of it first
off do you view it as something that
would have to be done federally because
obviously if you live in Los Angeles or
San Francisco your cost of living is way
higher than say if you live in Missouri
right so is this a is this a federal
program are we throwing this to the
state's imagine it needs to be done on a
national level and the reason is what
you can think of it's kind of like the
kind of adverse selection problem you
get in in insurance right if Los Angeles
has a basic income then people all over
the country are going to move to Los
Angeles to get that right and they're
gonna show up here and and overwhelm the
system so it needs to be national rather
then local right but what do you do
about the disparity and cost of living
in all these ways well you know one
issue there is that a basic income is
mobile right so maybe you don't have to
live in Los Angeles or San Francisco you
can take your basic income and you can
move to Detroit right and there you
might have a pretty decent life you can
have housing they're much cheaper right
so the difference between a basic income
and a job is that you can take it
everywhere so people would kind of
readjust and they might some people
might choose to leave leave high-cost
areas and and live in cheaper places and
so forth so how do you fund all this
that always is the big one are you
scrapping all the social programs that
exist right now or you're taxing
billionaires out the wazoo some
combination there you know do you think
definitely you need to raise more
revenue I think inevitably one of the
things that that we are seeing with the
economy largely as the result of
technology is that more and more income
is going to capital unless it's going to
labour so businesses and investors and
people like that are getting more income
and average working people are getting
less so what that means for the future I
think it's inevitable that we're gonna
have to tax capital more and labor less
and that may you know involve higher
business taxes or taxes on the
wealthiest people that have accessed a
lot lots of capital mean that that's as
a libertarian you might find that
objectionable but I think it's
inevitable you ultimately if you're
gonna have a taxation scheme you have to
tax the people to have the money right
you can't you can't get blood from a
rock as they say right right so well how
do you decide what the level is now I
get you could live in LA and the cost of
living is high and then maybe you'd say
alright well I can't I can't make it
here in a way I want to so I want to go
somewhere achieve but how do you figure
out well what is it that is the basic
stuff and the record well you know it's
ubi so what is the basic stuff that
people are supposed to have well I mean
the in terms of the level of the income
most people are talking about around a
thousand dollars a month Finland had an
experiment where it was like 600 euros
or something so these are pretty low
amounts I mean you know try you imagine
living on a thousand dollars a month
right
I used to do it yeah it's not so easy so
I think one advantage of these programs
is the they're gonna start at a low
level and we can imagine as technology
advances and and society becomes more
prosperous that that could be raised
over time but initially it's gonna be a
very low level so I don't think we have
to worry too much about destroying the
incentive for people to work and so
forth they give people a very very
minimal cushion but they're still gonna
have that incentive to work right it's
so interesting because it just does set
all my libertarian bells off that well
the second you give it to somebody so we
give a thousand bucks to everybody well
immediately you're gonna have
politicians saying this isn't enough and
it's then we have to make it more and we
have to make it more in that then that
becomes the cycle where we're always
shifting money around and it's just
because no one's ever gonna no matter
what basic level we get most people - no
one's ever gonna be like alright well
okay that's a real concern I would say
though that you know a basic income or
there are other flavors of the
guaranteed minimum income and negative
income tax these are ideas that in the
past have been embraced by libertarians
Friedrich Hayek was a big proponent of a
guaranteed minimum income Milton
Friedman was for a negative income tax
and the idea is that you're creating
really a market-based safety net right
rather than having government house
people feed people control industries or
try to take over businesses and run them
in a way that artificially creates jobs
and so forth rather than doing that just
give people some money let them go out
and participate in the market so it
actually is a market oriented
libertarian approach to having some kind
of safety net but I think your the idea
of it being politicized that's a real
concern one one thing I actually have
suggested and some of my writing is that
we might set up a separate institution
to kind of manage that maybe something
like the Federal Reserve mm-hmm it would
be independent and not part of the
political process and might manage the
level of of a basic income because you
could actually use it also to to respond
to recessions for example if there's an
economic down
maybe pay people a bit more mm-hmm and
then that would help you get out of the
recession right it would be kind of a
Keynesian response to it so I think
there are a lot of possibilities Debra
you're right we don't we don't want
every politician running on the platform
of I will increase your basic income
right that wouldn't be good right yeah
and that just strikes me as sort of real
politic related to all of this it's just
the way people are once you give them
something they want more I don't blame
people for that it's just sort of exact
the way people are the way politics work
so that's something that we need to
think about from the beginning as I said
you know maybe you put it in the hands
of a separate institution what other
thing I proposed is that maybe we can
build incentives into a basic income if
people stay in school paid them a bit
more than people that just play video
games where people go and work in the
community you know help other people pay
pay them a bit more so that I think it's
really important to have sort of a
ladder for people then they feel they
can somehow do better because that I
mean the issue you raised everywhere
raised before that we could create this
class of people that just you know do
nothing is is something to be concerned
about but there are ideas that we can I
think employ to really address that
right so what would you say to the
person listening that's going we'll wait
a minute thousand bucks I can't do
anything with the thousand bucks there's
basically no where I can get rent you
know how am I gonna do anything close to
living right so for most people now a
thousand dollars is not going to be
enough but it will provide a cushion
right so that's sort of the whole idea
we're starting off with a thousand
dollars and that's not gonna be enough
so you'll still have to work so is that
the point is that the biggest confusion
related to all this that I think people
here ubi and they think that it's just
enough just enough so you can get by but
you're saying that's actually not really
what's going on here
it may not be enough initially I mean
there may be some places in the country
not Los Angeles but some places you
could live on a thousand dollars so if
you were really in a bad situation and
you're living in LA you could pack up
and move somewhere where maybe a
thousand dollars will allow you to
survive right that's a possibility but I
think what most people will do is they
will take that thousand dollars and they
will use that to sort of cushion the
difficult times but they will still be
motivated to find a job to start a
business to do some
we just have more options more freedoms
in terms of the choices that they make
yeah and that's why you mentioned your
having Andrew yang and he actually calls
this program the the freedom dividend
that's what he's named and that's
exactly what it is it gives you more
options options especially for someone
that's living month-to-month and really
has no income you know the number of
choices do you have at in that scenario
which is very limited yeah I guess so
much of this has to do with just the
strange way we deal with politics so for
example you'll have you know politicians
saying we have to have $15 minimum wage
and then you can walk into Burger King
or McDonald's now and order on an iPad
because they're basically saying alright
we're not going to pay our people this
much so everything just becomes sort of
uber politicized right that's right and
and you know that that's why a basic
income is maybe a better approach
because we just give it to everyone and
the problem with raising the minimum
wage is that it may be you know good for
many workers but it can actually also
increase the incentive to automate or or
to do other things right so it could
actually result in fewer jobs so giving
people a basic income and preserving the
incentive for them to still work or to
do other things I think is a very
attractive proposition when you sort of
play out you know five 10 20 years from
now do you think things are gonna just
be beyond drastically different in a way
we really can't think about because of
the speed of all of this because of
everything we've talked about here that
we really can't even envision the way is
that I think if you go out maybe a
little further than that 20-30 years it
really really gets hard to imagine what
the future looks like my latest book
architects of intelligence wanted a
people it's a series of interviews with
the top people in AI one of the people I
talked to his Ray Kurzweil this is a big
futurist he thinks that it'll be alive
then yeah yeah yeah he absolutely thinks
he's gonna live forever he expects what
he calls the singularity something that
he's gonna completely change the whole
paradigm
he thinks did within just 10 years we're
gonna have human level artificial
intelligence and so forth so that's
possible
the problem is that is very
unpredictable we don't know how fast all
of this is coming what I really focus
dawn is sort of the practical impacts of
AI and robotics and impact on the job
market some what I would say is that
within five to ten years we're gonna
definitely see a fairly dramatic and an
unambiguous impact on the job market and
on the economy on i.t so ray is
basically gonna live long enough to see
the robots take over what one way or
another what he believes yeah you know
ray is he's already 70 but if you've
seen his photos recently he looks a lot
younger than he did a while ago so he's
at least he's had some work done yeah
but whether the end you know the stuff
under the hood is is is better or not
but right is he the only person doing
that sort of thing there must be some
other people oh no you know in Silicon
Valley there are many people very
interested in this idea of living
forever and advanced it you know the
Google people Larry Page and Sergey and
Peter Thiel is very into this as well as
even I think played around with
supposedly blood transfusions and stuff
like that so yes the the Silicon Valley
elite is you know they're true believers
in terms of this idea that technology is
going to completely transform things and
the future is going to be dramatically
different from the past and that we're
gonna potentially even have the
possibility of living forever yeah can
you explain the singularity the
singularity basically means a point at
which technology takes off and begins
accelerating at a rate that becomes
incomprehensible to us so they it comes
from basically a black hole right the
center of a black hole is what's called
a singularity where the laws of physics
break down and you can see beyond that
point so this the term singularity was
coined as a way to express the idea that
technology reaches a point where it's
just completely unpredictable beyond
that point because things are moving so
fast and most people that think about
this associate that with the advance of
what's called super intelligence or
machines that are smarter than us not
only human level intelligence but a
machine that you know is smarter than
any human being may be dramatically so
may be so smart that it makes us look
like a mouse or an insect
right so that's where my sci-fi brain
and every movie that I've ever seen and
every dystopian future says well why
would the robots need us at that point
exactly and if anything wouldn't they
just see us as an annoying hindrance or
a vestige of the past and why wouldn't
they want to get rid of us
right and that's a real concern and that
concern which is what you see in the
Terminator movies right and and even
more than that the the related concern
of what's called the control problem
which is that if we created a super
intelligence something that's far beyond
us maybe it won't actively want to
destroy us but it might act in ways that
are not you know that was right that was
our robot right and there are very very
serious thinkers that are focused on
this the money the most prominent ones
is Nick Bostrom who I also interviewed
in my latest book Architects of
intelligence so he you know believes
that this is a real issue and he's
working on finding ways to build systems
that will be controllable even if they
become super intelligence mm-hmm so this
is an issue that he's focused on also
the inherent problem being that if you
create the super intelligence it
probably at some point can get around
that I mean I know that's not
mind-blowing to him but that's the whole
idea is that once we have a super
intelligence then you know it's so far
beyond us that we can't control it
anymore so what what people are working
on is basically principles of computer
science that will hopefully allow them
to build these systems in a way that
that will remain aligned with what we
want them to do even when they're super
intelligent right but is the problem
with that what we hit on earlier which
is maybe we here in America hopefully
figure out some systems that are gonna
make some sense but if the Chinese
figure out a system that's a little bit
different or just some random guy in his
garage in Mexico I think is out some
other thing that we still have that that
basically there's just no way to manage
it seems yeah I think that's one of the
scariest aspects of this is that
competition and the fact that there
would be an incredible first mover
advantage to whoever gets there first
mm-hmm whoever builds the first super
intelligent system you know is gonna be
way ahead of everyone else and a reason
is that most people believe in what's
called an intelligence explosion or kind
of iterative improvement where basically
once a machine reaches human level
intelligence or gets beyond that it's
gonna turn its attention to its own code
right to building better versions of
itself so it's gonna continuously
engineer a smarter version of itself and
that's something that could explode
rapidly so whoever gets there first
they're essentially uncatchable so that
is gonna set up a competitive
environment between the US and China and
Russia and so forth yeah so that's
something to worry about but there are a
lot of people working on doing this in a
safe way open AI is another good example
that's the the organization that was set
up by Elon Musk right and some other
people and they're actively working on
building systems that basically they're
trying to get their first to be the
first one to to create a generally
intelligent system and to do it in a way
that is safe so I think that's a good
thing there's there's some real focus on
that and investment in that area but at
the same time there's also a lot of hype
yeah people like Elon saying some pretty
over-the-top things I do think that to
some extent that's a bit dangerous
because it again this is something that
is probably pretty far in the future I
would say probably at least 50 years of
away there is a big debate over that
again in my latest book I interviewed
all these people I asked them this
question how soon are we gonna have a
computer that is at the level of a human
being in terms of intelligence and the
predictions I got ranged from 10 years
from Ray Kurzweil to nearly 200 years
Wow so it is a wide variation that the
average guess was about 80 years so the
end of this century so pretty far what
are the markers that cause people to
have a different response to that
question so why would someone like her
while say 10 and then someone else says
200 well you know there are a number of
breakthroughs do you have to have you
have to have machines that can learn the
way people learn right now as I said
we've got machine learning deep learning
which is highly dependent on lots and
lots of data and their particular label
data so you can train one of these
algorithms to recognize pictures of a
dog and you would give it maybe a
million photographs that had
that was you know these photos would be
labeled either there's a dog there or
there's not a dog there and you based on
this it could learn and eventually
recognize dogs at a superhuman level but
that's not the way a human child learns
right a human child you can you can
point to a dog and maybe you only need
to do that once before the kid needs to
learn and so one of the biggest
initiatives is teaching machines to
learn from less data and in an
unsupervised way in the way that that
people can and then you've got to have
the ability to think generally to
conceive new ideas to be creative to
understand that one thing causes another
thing as opposed to just two things
being correlated to develop
counterfactuals to imagine I've got this
plan for the future but if I tweak this
one thing then this is what's gonna be
different these are all uniquely human
ways of thinking and it's going to take
a lot of breakthroughs before we have a
machine that can do all those things and
there's just a lot of disagreement even
between the very smartest people working
this field about how long it's going to
take for those kinds of breakthroughs to
happen how concerned are you about the
unbiased
that seems to be happening when it comes
to the algorithm so for example you know
the famous case that everyone talks
about is that if you google American
scientists that there's that it happens
to be it's just a function of things
that most emeritus American scientists
who have done most of the breakthroughs
most not all happen to be white men but
that Google is unbiased so it includes
more black people or more women or
things like that which nobody has a
problem with no one in their right mind
has a real problem acknowledging that
there are scientists of every color and
gender and all of those things but
they're unbiased things that are that
are not so it's not really factual sort
of what we're putting in the algorithm
and that where that could lead us seems
right that's ultimately a decision for
society I suppose how we want to address
those issues of them the whole issue of
bias in in algorithms is a huge issue in
artificial intelligence people are
working on reducing that and that that
operates in both ways I mean they're
definitely an absolutely have been
legitimate cases of algorithms that are
biased against people of color and so
forth
for example and gender - I mean I know
that one company for example stopped
using an AI system that was used to
screen resumes because it was biased
against women hmm and so forth and there
been other and where does that buyers
come from in a situation is you know
what happens is that again these are
systems that are learning from data
right but where does that data come from
originally it comes from people mm-hmm
so if people are biased in some way and
they're generating this data then an
algorithm a machine learning algorithm
comes along and it's trained on that
data it will pick up that bias
so basically we're the flaw in the
system absolutely more than anything
else really right but there is a hopeful
note there which is that fixing bias in
a human being is very hard right I mean
we don't really know how to do that and
we know that it does exist to some
extent but fixing it in an algorithm
could be a lot easier right it's
basically tweaking some bits so as we I
guess it depends who's doing it though
right exactly as long as as long as it's
done in a careful proper way but we
can't imagine a future where algorithms
as they're employed more maybe as kind
of a check on decisions or maybe in some
cases actually making decisions it can
actually be a less biased world and not
not a more by squirrel but you're right
there are a huge numbers of issues
running in both directions there yeah
well it's funny that that's sort of the
theme of all of this because I'm even
trying to sort of figure out as you're
talking are you optimistic about this or
or pessimistic about sort of where this
could all lead and I definitely sense
both sides there yeah I mean I tend to
be you know it's speaking more
holistically including you know there
are many many issues with AI things that
we should be concerned about bias is one
security the abyss the ability of people
bad people to hack into a system and and
do evil things with it the potential for
weaponization is another thing that many
people are really really worried about
the idea that you can have autonomous
weapons not just one autonomous weapon
that might independently kill people
without a human in the loop but you
could have thousands of them swarming
right without that's this guy definitely
terrifying
and this is something that you know is
is not really science fiction I mean we
were talking earlier about super
intelligence and determinated where the
machines actively are making a choice to
kill us that's science fiction that lies
far in the future but the idea of having
thousands of swarming autonomous drones
that were not intelligent independently
but were you know programmed by somebody
else to do something to attack someone
or so so basically something that could
happen so the idea being that okay
Amazon moves to drone delivery and then
someone hacks into the system and
instead of these drones dropping
packages at our door they're flying
through our windows and the street could
be happy or whatever or it could be
someone you know manufacturing a huge
numbers of these drones and and and
installing autonomous software because
double you know the barrier to entry
here is pretty low I mean these are
these are weapons that some people could
be like weapons of mass destruction if
you had enough autonomous drones that
would be incredibly dangerous right now
if you look at something like nuclear
weapons in order for a country to have
nuclear weapons they you know you've got
to be a nation state you gotta have love
you know resources on that level in
order to develop nuclear weapons but
these kinds of technologies where you're
talking you know and there's a lot of
overlap between the commercial sector
and things that could be done on the
security or military side you can go on
Amazon you could purchase a thousand
drones and then maybe you could you know
engineer them to be to be weapons or
something these are something that you
know there's a much lower threshold
there people in a basement somewhere it
could be doing this kind of stuff right
so it is it but right now well I I think
they know already but it is quite scary
and many people in the IR community are
very passionate about this in particular
there there's an initiative in the
United Nations to actually ban fully
autonomous weapons for example and the
real worry is not just that militaries
would use these kinds of weapons but it
would go beyond that and you would have
you know that kind of shady arms dealers
that now sell machine guns are selling
autonomous drones and so that they then
become available to terrorists and all
kinds of people and this is a really
scary scenario yeah one of the people I
interviewed Stewart Russell who's a
professor at UC Berkeley created a
YouTube video code slaughter bots that
you can go on and watch and it's really
quite terrifying and it shows you
exactly what could be done with huge
numbers of swarming autonomous drones
and it's not again it's not science
fiction it's something that could happen
in the next 5-10 years yeah do you are
you familiar at all with just sort of
the anti technology movement the more
that you pay attention to the technology
movement and the amount of people that
are trying to either get off the grid or
limit the amount of time online and that
whole thing right I mean I you know that
that's I think a natural response to a
lot of this I mean the the the worst
example of that is is Ted Kaczynski
right the Unabomber right who actually
wrote a manifesto that he was published
I think in the New York Times um but if
you go and read that manifesto this is a
guy that okay he's crazy right he's a
murderer all of this but if you read
that manifesto and not know that it was
written by him he's raising a lot of the
issues that we are now talking about you
know the issues that technology could be
a threat the issue that we might become
so dependent on this technology that we
lose our agency right our ability to
think for ourselves and so far so you
know even back then these people like
we're thinking about this and so this is
a natural response and one of the things
I fear the most is that if we don't find
a way to adapt to these technologies and
find a way to leverage all this progress
on behalf of everyone so that everyone
is better off there's gonna be a bigger
and bigger backlash people are gonna
turn against the technology and that
might mean not just going off the grid
and living you know as a hermit but
actually be you know becoming much more
adversarial to the system and and that
might happen politically it might happen
in some places even in the form of
social unrest and so forth as things get
get bad enough if we really have
unemployment so I just think it's
critically important that we begin to
really address these issues and have a
honest discussion about them so that we
can avoid that scenario I assume you're
a fan of black mirror
I haven't really watched that but I've
heard a lot about it but but yeah that
those kinds of scenarios are you know
science fiction now but they are
everyday becoming reality yeah is there
a sci-fi movie that you think handles
some of this in the best way so not
going all the way to Terminator tomorrow
but like there's some movies that you
think have sort of teased out some of
the the more realistic clothes refused
yeah there are several there's one movie
a few years ago called Elysium yeah
which really got at the issue of
inequality because what happened you
know that's the one with the notice yeah
I love artificial earth
yeah or and all the rich people yeah
migrated there on earth DoD foster
became basically you know a dystopian
nightmare all the regular people were
stuck on earth and that's you're seeing
that already of course with wealthy
people moving to gated communities and
so forth and elite cities like San
Francisco where things are becoming so
unequal and I really worry that that's
the kind of future we could have if we
don't adapt to this where you literally
have got a small number of incredibly
wealthy people that are benefiting from
this technology and or maybe using the
technology to protect themselves from
the masses right and everyone else is
literally left behind so that that's
sort of the ultimate irony of what's
happening in Silicon Valley right I mean
you just said it it's like San Francisco
they've got all these great minds are up
there creating all this incredible
technology absurd amounts of wealth and
then if you go out on the streets of San
Francisco the amount of homelessness is
is the room yeah yeah I mean everything
else San Francisco and the Bay Area is
ground zero for this technological
revolution and then right in their
backyard you see you see the inequality
right you see what's happening and this
is something that's gonna scale out
right to everywhere
basically so we really need to get
control of that and if we don't it's I
think it's gonna tear our society apart
right it's gonna ultimately lead to some
real problems in the United States and
in other countries that are less stable
that have less you know solid
institutions that we have it it could be
even worse you're gonna see government's
fall and things like that in some
countries as a result of this I think so
it's really some
to be concerned about we need we need to
have some sort of a plan yeah well
that's what everyone's trying to figure
out right now is is what is that plan
exactly and I think this is one of the
biggest challenges we're going to face
in the future you know this is AI is
going to be one of the primary forces
that shapes the future it's going to be
incredibly disruptive and of course it's
going to happen in parallel with other
things climate change geopolitically the
rise of china migration right these are
all huge things that are happening
already all these things are coming at
is in parallel they're gonna hit all
together and I really worry about kind
of a perfect storm so we really need to
begin to get a handle on all how does
the information war factor into all of
this you know one of the things that
people that watch this show or always
talk you know everyone's talking about
fake news all the time or that we're
just being handed things you know the
algorithm pushes us stories that are
favorable maybe to one side of the
political aisle or something like that
and that we're all going to also siphon
off into our own informational realities
basically and sort of we'll live in the
same physical world but digitally we're
gonna just accept different truths
exactly in that that that's what makes
it even more scary as to all of this
disruption is coming at us at a time
when we are just incredibly polarized
where to some extent we're living in
different universes our ability to even
talk to each other seems to be limited
how are we gonna you know address these
issues how are we gonna respond to these
incredibly disruptive forces when we
can't even sit down and have a
conversation and agree on the same facts
right that's a real problem and and
there is evidence that is getting worse
and worse that's largely that's why I'm
doing this this is this is my little
firewall right here but exactly I hope
that there there can't be more of this
because we really need everyone and that
includes people on the left and people
on the right to be able to talk to each
other about this because otherwise we're
gonna have what we have now anybody
we've got a Congress that literally can
do nothing and I'm concerned no matter
who wins in 2020 the presidency you know
it's likely that the Congress will still
be divided by the same political
polarization and social polarization and
social media
we'll be there so how are we gonna
address these kinds of issues so that
gets to what you were talking about
earlier that you need something sort of
separate from the government in a way to
sort of be if if something could oversee
some of our ability to deal with this
technology it almost in a way it can't
be politicized because of the way our
system is right I mean is specifically
in terms of having a basic income I
think there are good reasons to put that
in the hands of a separate institution
and the Federal Reserve would be a good
example of that you've seen the Federal
Reserve which controls interest rates
right he's relatively independent right
now although you know trombley's tried
to to to play around with it but you
know if it weren't for the fact that we
had an independent Federal Reserve I
think we would be much bigger trouble
now than we are and so there is an
argument for maybe taking some essential
functions of government away from the
political process and having a kind of a
technocratic approach to that all right
so my last question will be a two-parter
paint me a future if we get some of this
under control and we deal with this
technology maturely and properly give me
sort of where what do we look like in
about 10 years and then if we lose
control and we don't do the proper
things and don't have the proper
firewalls what is the future look like
continues well I think that you know
maybe looking even beyond 10 years we
know one is how far do you want to go
well let's say 15 20 year okay but I
think that within that kind of a time
frame there's gonna be an unambiguous
impact on on a job market so if we don't
get control of this we will see
unemployment at least among some workers
will see greatly increased inequality
even beyond what we see now we will see
more and more anger more people left
behind possibly even social unrest as a
result of that we will see the rise of
people like Trump which you might
characterize as kind of a demagogue
someone that preys on the fear that
people have right maybe you know points
to to immigrants as opposed to
technology as being the primary cause of
this and so forth right those other
people are stealing your job it's a lot
easier to always point to another human
being than it is to
point to an intangible force like
technology so we could have a future
where you know everything is just very
very ugly and a lot of people are really
struggling don't hang me on that future
and and the other part of that though is
that there's also an economic aspect to
that that as people are unemployed or
have lower incomes they have less money
to spend right now they're not driving
the economy so the whole economy suffers
so we could have also a financial crisis
a recession perhaps people can't pay
their debts and we get into a situation
like we had in 2008 right so that's
that's sort of a worst-case scenario the
best-case scenario is that we find a way
to adapt to this maybe it was something
like a basic income so we address this
issue of people not having jobs or not
having adequate income so they still
have money to spend they go out and they
spend their money in the economy there
are all kinds of new products and
services and exciting things for people
to spend money on there is incredible
opportunity for entrepreneurs for people
like Elon Musk's or the next Steven
Steve Jobs to create things based on
this new technology and people have the
income that they need to to buy these
products things do in large measure get
less expensive so people you know have
have greater purchasing power we have
enormous breakthroughs in science in
medicine we all live longer and
healthier lives so there are enormous
benefits to artificial intelligence it's
going to become the primary tool that's
used in scientific research in solving
problems like climate change developing
new forms of clean energy you know
medical breakthroughs all of that the
key thing is that we want to make sure
that we get that stuff and then we get
it for everyone in other words we want
to be able to leverage it on behalf of
everyone rather than just a few people
and I think that if we can find a way to
navigate through this that it's
incredibly optimistic and and where it
kind of ends up in the far future is
maybe something like Star Trek right
where you've got what has been called
kind of the post-scarcity economy an
economy of abundance where you know
people don't have to worry about the
basics of life anymore that
and people you know focus on other
things right I mean in Star Trek you've
got the materializer right you
everything is basically free people
don't have to work a nine-to-five job to
survive they are out traveling the
universe or whatever doing things that
are genuinely meaningful to them and I
think that's sort of the vision that we
should have as we you know anticipate
the development of these technologies
but in order to get there we've got to
be honest there's some serious lift
about what the implications of this is
we need to have an honest discussion and
come up I think ultimately with some
real policies to address the risks and
the downsides that are gonna come with
this progress so we shall see are the
three words that all sort of take us out
of this one we should probably do this
every year you want to do one of these
every year absolutely and just pick up
on all the incremental progress and then
I suppose if everything you're saying is
right one year we're gonna do it and
everything will look so absolutely
different we won't even be able to look
back and make any sense of all right
once we get past that singularity will
be different I look forward to it and
for more on Martin you can follow him on
Twitter at M Ford future
[Music]
